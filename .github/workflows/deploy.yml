name: Deploy
on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: write # To push a branch
      pull-requests: write # To create a PR from that branch
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
      - name: Install latest mdbook
        run: |
          tag=$(curl 'https://api.github.com/repos/rust-lang/mdbook/releases/latest' | jq -r '.tag_name')
          url="https://github.com/rust-lang/mdbook/releases/download/${tag}/mdbook-${tag}-x86_64-unknown-linux-gnu.tar.gz"
          mkdir mdbook
          curl -sSL $url | tar -xz --directory=./mdbook
          echo `pwd`/mdbook >> $GITHUB_PATH
      - name: Deploy GitHub Pages
        run: |
          # This assumes your book is in the root of your repository.
          # Just add a `cd` here if you need to change to another directory.
          mdbook build
          git worktree add gh-pages
          git config user.name "Deploy from CI"
          git config user.email ""
          cd gh-pages
          # Delete the ref to avoid keeping history.
          git update-ref -d refs/heads/gh-pages
          rm -rf *
          mv ../book/* .
          git add .
          git commit -m "Deploy $GITHUB_SHA to gh-pages"
          git push --force --set-upstream origin gh-pages
          
      - name: Install and Configure rclone
        run: |
          # Install rclone
          curl https://rclone.org/install.sh | sudo bash
          
          # Configure rclone for S3 compatible storage
          mkdir -p ~/.config/rclone
          cat > ~/.config/rclone/rclone.conf << EOF
          [s3]
          type = s3
          provider = Other
          env_auth = false
          access_key_id = ${{ secrets.S3_ACCESS_KEY }}
          secret_access_key = ${{ secrets.S3_SECRET_KEY }}
          endpoint = ${{ secrets.S3_ENDPOINT_URL }}
          acl = public-read
          bucket_acl = public-read
          storage_class = STANDARD
          no_check_bucket = true
          EOF
          
      - name: Deploy to S3-compatible storage with rclone
        run: |
          # Navigate to where the built files are
          cd gh-pages
          
          # Print info about deployment
          echo "Using rclone to upload to S3-compatible storage"
          echo "Bucket: ${S3_BUCKET_NAME_MASKED}"
          
          # Test connection
          echo "Testing connection to S3-compatible storage..."
          if rclone ls s3:${{ secrets.S3_BUCKET_NAME }} --quiet; then
            echo "✅ Bucket exists and is accessible"
          else
            echo "❌ Bucket does not exist or is not accessible"
            exit 1
          fi
          
          # Create a helper script to upload files with proper Content-Type
          cat > upload.sh << 'EOF'
          #!/bin/bash
          BUCKET=$1
          
          # Common file types and their MIME types
          declare -A mime_types
          mime_types["html"]="text/html"
          mime_types["htm"]="text/html"
          mime_types["css"]="text/css"
          mime_types["js"]="application/javascript"
          mime_types["json"]="application/json"
          mime_types["png"]="image/png"
          mime_types["jpg"]="image/jpeg"
          mime_types["jpeg"]="image/jpeg"
          mime_types["gif"]="image/gif"
          mime_types["svg"]="image/svg+xml"
          mime_types["webp"]="image/webp"
          mime_types["pdf"]="application/pdf"
          mime_types["woff"]="application/font-woff"
          mime_types["woff2"]="application/font-woff2"
          mime_types["txt"]="text/plain"
          mime_types["md"]="text/plain"
          
          # First sync everything as binary to ensure all files get transferred
          echo "Syncing all files (initial pass)..."
          rclone sync --verbose --progress \
            --checksum \
            --update \
            --delete-after \
            --exclude ".git/**" \
            --exclude "upload.sh" \
            --s3-no-check-bucket \
            ./ s3:${BUCKET}
            
          # Now set the correct Content-Type and Content-Disposition for common file types
          echo "Setting correct Content-Type for files..."
          
          for ext in "${!mime_types[@]}"; do
            echo "Processing *.${ext} files with MIME type: ${mime_types[$ext]}"
            
            # Find all files with this extension
            find . -type f -name "*.${ext}" | while read file; do
              file_path=${file#./}
              echo "Setting metadata for: $file_path"
              
              # Set the content-type and disposition
              rclone touch s3:${BUCKET}/${file_path} \
                --metadata="Content-Type=${mime_types[$ext]}" \
                --metadata="Content-Disposition=inline"
            done
          done
          
          # For any other files, at least set Content-Disposition
          echo "Setting Content-Disposition for remaining files..."
          rclone lsf s3:${BUCKET} --recursive | grep -v -E '\.(html|htm|css|js|json|png|jpg|jpeg|gif|svg|webp|pdf|woff|woff2|txt|md)$' | while read file; do
            echo "Setting Content-Disposition for: $file"
            rclone touch s3:${BUCKET}/$file --metadata="Content-Disposition=inline"
          done
          
          echo "Upload completed with proper metadata."
          EOF
          
          # Make script executable
          chmod +x upload.sh
          
          # Run the upload script
          ./upload.sh ${{ secrets.S3_BUCKET_NAME }}
            
          echo "Successfully deployed to S3-compatible storage"
        env:
          # Mask sensitive data in logs
          S3_BUCKET_NAME_MASKED: "${{ secrets.S3_BUCKET_NAME }}"
